{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4fb16ac",
   "metadata": {
    "_cell_guid": "e0e4bdf6-bcd9-4f82-a53b-9c5f685500a8",
    "_uuid": "66c995cf-7cbb-421b-bdd3-24906f5fb886",
    "execution": {
     "iopub.execute_input": "2022-01-05T18:19:34.766525Z",
     "iopub.status.busy": "2022-01-05T18:19:34.765636Z",
     "iopub.status.idle": "2022-01-05T18:19:43.074135Z",
     "shell.execute_reply": "2022-01-05T18:19:43.072934Z",
     "shell.execute_reply.started": "2022-01-05T18:19:34.76641Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.016175,
     "end_time": "2022-03-15T16:25:09.176928",
     "exception": false,
     "start_time": "2022-03-15T16:25:09.160753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Welcome back !\n",
    "\n",
    "Inspired from [this notebook](https://www.kaggle.com/fxalll/0-690-try-better-parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35071595",
   "metadata": {
    "papermill": {
     "duration": 0.014902,
     "end_time": "2022-03-15T16:25:09.207310",
     "exception": false,
     "start_time": "2022-03-15T16:25:09.192408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import Librairie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e0c55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:25:09.241481Z",
     "iopub.status.busy": "2022-03-15T16:25:09.239990Z",
     "iopub.status.idle": "2022-03-15T16:25:15.956941Z",
     "shell.execute_reply": "2022-03-15T16:25:15.957463Z",
     "shell.execute_reply.started": "2022-03-15T15:10:10.307018Z"
    },
    "papermill": {
     "duration": 6.735844,
     "end_time": "2022-03-15T16:25:15.957725",
     "exception": false,
     "start_time": "2022-03-15T16:25:09.221881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../input/tez-lib/\")\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tez\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from joblib import Parallel, delayed\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0748de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:25:15.993186Z",
     "iopub.status.busy": "2022-03-15T16:25:15.989170Z",
     "iopub.status.idle": "2022-03-15T16:25:17.648762Z",
     "shell.execute_reply": "2022-03-15T16:25:17.648273Z",
     "shell.execute_reply.started": "2022-03-15T15:25:42.731569Z"
    },
    "papermill": {
     "duration": 1.676518,
     "end_time": "2022-03-15T16:25:17.648892",
     "exception": false,
     "start_time": "2022-03-15T16:25:15.972374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modules\n",
    "import re\n",
    "import sys; sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "import time\n",
    "\n",
    "import datatable as dt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from bs4 import BeautifulSoup\n",
    "from datasets import Dataset\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from termcolor import colored\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83445772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:25:17.687004Z",
     "iopub.status.busy": "2022-03-15T16:25:17.686222Z",
     "iopub.status.idle": "2022-03-15T16:25:17.688643Z",
     "shell.execute_reply": "2022-03-15T16:25:17.688210Z",
     "shell.execute_reply.started": "2022-03-15T15:10:17.395929Z"
    },
    "papermill": {
     "duration": 0.024353,
     "end_time": "2022-03-15T16:25:17.688747",
     "exception": false,
     "start_time": "2022-03-15T16:25:17.664394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_id_map = {\n",
    "    \"B-Lead\": 0,\n",
    "    \"I-Lead\": 1,\n",
    "    \"B-Position\": 2,\n",
    "    \"I-Position\": 3,\n",
    "    \"B-Evidence\": 4,\n",
    "    \"I-Evidence\": 5,\n",
    "    \"B-Claim\": 6,\n",
    "    \"I-Claim\": 7,\n",
    "    \"B-Concluding Statement\": 8,\n",
    "    \"I-Concluding Statement\": 9,\n",
    "    \"B-Counterclaim\": 10,\n",
    "    \"I-Counterclaim\": 11,\n",
    "    \"B-Rebuttal\": 12,\n",
    "    \"I-Rebuttal\": 13,\n",
    "    \"O\": 14,\n",
    "    \"PAD\": -100,\n",
    "}\n",
    "\n",
    "\n",
    "id_target_map = {v: k for k, v in target_id_map.items()}\n",
    "\n",
    "class args1:\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/longformerlarge4096/longformer-large-4096/\"\n",
    "    tez_model= \"../input/fblongformerlarge1536/\"\n",
    "    output = \".\"\n",
    "    batch_size = 8\n",
    "    max_len = 4096\n",
    "    \n",
    "class args2:\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/longformerlarge4096/longformer-large-4096/\"\n",
    "    tez_model= \"../input/tez-fb-large/\"\n",
    "    output = \".\"\n",
    "    batch_size = 8\n",
    "    max_len = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "529fc8bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:25:17.725181Z",
     "iopub.status.busy": "2022-03-15T16:25:17.724424Z",
     "iopub.status.idle": "2022-03-15T16:25:17.726802Z",
     "shell.execute_reply": "2022-03-15T16:25:17.726376Z",
     "shell.execute_reply.started": "2022-03-15T15:10:17.415888Z"
    },
    "papermill": {
     "duration": 0.023408,
     "end_time": "2022-03-15T16:25:17.726901",
     "exception": false,
     "start_time": "2022-03-15T16:25:17.703493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedbackDataset:\n",
    "    def __init__(self, samples, max_len, tokenizer):\n",
    "        self.samples = samples\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.length = len(samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.samples[idx][\"input_ids\"]\n",
    "        # print(input_ids)\n",
    "        # print(input_labels)\n",
    "\n",
    "        # add start token id to the input_ids\n",
    "        input_ids = [self.tokenizer.cls_token_id] + input_ids\n",
    "\n",
    "        if len(input_ids) > self.max_len - 1:\n",
    "            input_ids = input_ids[: self.max_len - 1]\n",
    "\n",
    "        # add end token id to the input_ids\n",
    "        input_ids = input_ids + [self.tokenizer.sep_token_id]\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        return {\n",
    "            \"ids\": input_ids,\n",
    "            \"mask\": attention_mask,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ccec0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:25:17.765343Z",
     "iopub.status.busy": "2022-03-15T16:25:17.763714Z",
     "iopub.status.idle": "2022-03-15T16:25:17.767591Z",
     "shell.execute_reply": "2022-03-15T16:25:17.767173Z",
     "shell.execute_reply.started": "2022-03-15T15:10:17.434399Z"
    },
    "papermill": {
     "duration": 0.026008,
     "end_time": "2022-03-15T16:25:17.767699",
     "exception": false,
     "start_time": "2022-03-15T16:25:17.741691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        output = dict()\n",
    "        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n",
    "        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n",
    "\n",
    "        # calculate max token length of this batch\n",
    "        batch_max = max([len(ids) for ids in output[\"ids\"]])\n",
    "\n",
    "        # add padding\n",
    "        if self.tokenizer.padding_side == \"right\":\n",
    "            output[\"ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"ids\"]]\n",
    "            output[\"mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"mask\"]]\n",
    "        else:\n",
    "            output[\"ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"ids\"]]\n",
    "            output[\"mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"mask\"]]\n",
    "\n",
    "        # convert to tensors\n",
    "        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n",
    "        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b3038a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:25:17.805095Z",
     "iopub.status.busy": "2022-03-15T16:25:17.804564Z",
     "iopub.status.idle": "2022-03-15T16:25:17.807769Z",
     "shell.execute_reply": "2022-03-15T16:25:17.807380Z",
     "shell.execute_reply.started": "2022-03-15T15:10:17.455201Z"
    },
    "papermill": {
     "duration": 0.025029,
     "end_time": "2022-03-15T16:25:17.807867",
     "exception": false,
     "start_time": "2022-03-15T16:25:17.782838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedbackModel(tez.Model):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "        hidden_dropout_prob: float = 0.2\n",
    "        layer_norm_eps: float = 17589e-7\n",
    "        config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"layer_norm_eps\": layer_norm_eps,\n",
    "                \"add_pooling_layer\": False,\n",
    "            }\n",
    "        )\n",
    "        self.transformer = AutoModel.from_config(config)\n",
    "        self.output = nn.Linear(config.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        transformer_out = self.transformer(ids, mask)\n",
    "        sequence_output = transformer_out.last_hidden_state\n",
    "        logits = self.output(sequence_output)\n",
    "        logits = torch.softmax(logits, dim=-1)\n",
    "        return logits, 0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a13d6782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:25:17.845110Z",
     "iopub.status.busy": "2022-03-15T16:25:17.844585Z",
     "iopub.status.idle": "2022-03-15T16:25:17.848139Z",
     "shell.execute_reply": "2022-03-15T16:25:17.847698Z",
     "shell.execute_reply.started": "2022-03-15T15:10:17.472430Z"
    },
    "papermill": {
     "duration": 0.025637,
     "end_time": "2022-03-15T16:25:17.848240",
     "exception": false,
     "start_time": "2022-03-15T16:25:17.822603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _prepare_test_data_helper(args, tokenizer, ids):\n",
    "    test_samples = []\n",
    "    for idx in ids:\n",
    "        filename = os.path.join(args.input_path, \"test\", idx + \".txt\")\n",
    "        with open(filename, \"r\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=False,\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        input_ids = encoded_text[\"input_ids\"]\n",
    "        offset_mapping = encoded_text[\"offset_mapping\"]\n",
    "\n",
    "        sample = {\n",
    "            \"id\": idx,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"text\": text,\n",
    "            \"offset_mapping\": offset_mapping,\n",
    "        }\n",
    "\n",
    "        test_samples.append(sample)\n",
    "    return test_samples\n",
    "\n",
    "\n",
    "def prepare_test_data(df, tokenizer, args):\n",
    "    test_samples = []\n",
    "    ids = df[\"id\"].unique()\n",
    "    ids_splits = np.array_split(ids, 4)\n",
    "\n",
    "    results = Parallel(n_jobs=4, backend=\"multiprocessing\")(\n",
    "        delayed(_prepare_test_data_helper)(args, tokenizer, idx) for idx in ids_splits\n",
    "    )\n",
    "    for result in results:\n",
    "        test_samples.extend(result)\n",
    "\n",
    "    return test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e388b769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:25:17.887845Z",
     "iopub.status.busy": "2022-03-15T16:25:17.887218Z",
     "iopub.status.idle": "2022-03-15T16:29:28.713336Z",
     "shell.execute_reply": "2022-03-15T16:29:28.712834Z",
     "shell.execute_reply.started": "2022-03-15T15:19:30.447386Z"
    },
    "papermill": {
     "duration": 250.850406,
     "end_time": "2022-03-15T16:29:28.713488",
     "exception": false,
     "start_time": "2022-03-15T16:25:17.863082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/it, stage=test]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it, stage=test]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it, stage=test]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it, stage=test]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it, stage=test]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it, stage=test]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it, stage=test]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it, stage=test]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it, stage=test]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it, stage=test]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\"../input/feedback-prize-2021/\", \"sample_submission.csv\"))\n",
    "df_ids = df[\"id\"].unique()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args1.model)\n",
    "test_samples = prepare_test_data(df, tokenizer, args1)\n",
    "collate = Collate(tokenizer=tokenizer)\n",
    "\n",
    "raw_preds = []\n",
    "for fold_ in range(10):\n",
    "    current_idx = 0\n",
    "    test_dataset = FeedbackDataset(test_samples, args1.max_len, tokenizer)\n",
    "    \n",
    "    if fold_ < 5:\n",
    "        model = FeedbackModel(model_name=args1.model, num_labels=len(target_id_map) - 1)\n",
    "        model.load(os.path.join(args1.tez_model, f\"model_{fold_}.bin\"), weights_only=True)\n",
    "        preds_iter = model.predict(test_dataset, batch_size=args1.batch_size, n_jobs=-1, collate_fn=collate)\n",
    "    else:\n",
    "        model = FeedbackModel(model_name=args2.model, num_labels=len(target_id_map) - 1)\n",
    "        model.load(os.path.join(args2.tez_model, f\"model_{fold_-5}.bin\"), weights_only=True)\n",
    "        preds_iter = model.predict(test_dataset, batch_size=args2.batch_size, n_jobs=-1, collate_fn=collate)\n",
    "        \n",
    "    current_idx = 0\n",
    "    \n",
    "    for preds in preds_iter:\n",
    "        preds = preds.astype(np.float16)\n",
    "        preds = preds / 10\n",
    "        if fold_ == 0:\n",
    "            raw_preds.append(preds)\n",
    "        else:\n",
    "            raw_preds[current_idx] += preds\n",
    "            current_idx += 1\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69923780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:29:28.798067Z",
     "iopub.status.busy": "2022-03-15T16:29:28.792817Z",
     "iopub.status.idle": "2022-03-15T16:29:28.954202Z",
     "shell.execute_reply": "2022-03-15T16:29:28.953736Z",
     "shell.execute_reply.started": "2022-03-15T15:24:05.569929Z"
    },
    "papermill": {
     "duration": 0.213117,
     "end_time": "2022-03-15T16:29:28.954315",
     "exception": false,
     "start_time": "2022-03-15T16:29:28.741198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pred_logreg():\n",
    "    ### Parameters\n",
    "    DEBUG_FLAG = False\n",
    "    VERSION = 'nb08'\n",
    "\n",
    "    SUBMISSION_PATH = '/kaggle/input/feedback-prize-2021/sample_submission.csv'\n",
    "    TRAIN_PATH = '/kaggle/input/feedback-prize-2021/train.csv'\n",
    "    TRAIN_DIR = '/kaggle/input/feedback-prize-2021/train'\n",
    "    TEST_DIR = '/kaggle/input/feedback-prize-2021/test'\n",
    "\n",
    "    N_SPLITS = 5 if not DEBUG_FLAG else 2\n",
    "    TEXT_MIN_LENGTH = 4\n",
    "    \n",
    "    ### Install\n",
    "    !pip install --no-deps ../input/datasets-1183/datasets-1.18.3-py3-none-any.whl\n",
    "    !pip install --no-deps ../input/chaii-python-module-installers/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl\n",
    "    \n",
    "    ### My functions\n",
    "    def read_df():\n",
    "        train = dt.fread(TRAIN_PATH).to_pandas()\n",
    "        train['discourse_id'] = train['discourse_id'].astype(int)\n",
    "        train['discourse_start'] = train['discourse_start'].astype('int16')\n",
    "        train['discourse_end'] = train['discourse_end'].astype('int16')\n",
    "        submission = dt.fread(SUBMISSION_PATH).to_pandas()\n",
    "\n",
    "        print(f'train shape: {train.shape}')\n",
    "        print(f'submission shape: {submission.shape}')\n",
    "\n",
    "        train_files = os.listdir(TRAIN_DIR)\n",
    "        train_files.sort()\n",
    "        print(f'number of train_files: {len(train_files)}')\n",
    "\n",
    "        test_files = os.listdir(TEST_DIR)\n",
    "        test_files.sort()\n",
    "        print(f'number of test_files: {len(test_files)}')\n",
    "\n",
    "        train_id2text = []\n",
    "        for train_file in train_files:\n",
    "            with open(os.path.join(TRAIN_DIR, train_file), 'r') as f: text = f.read()\n",
    "            train_id2text.append((train_file.replace('.txt', ''), text))\n",
    "\n",
    "        test_id2text = []\n",
    "        for test_file in test_files:\n",
    "            with open(os.path.join(TEST_DIR, test_file), 'r') as f: text = f.read()\n",
    "            test_id2text.append((test_file.replace('.txt', ''), text))\n",
    "\n",
    "        if DEBUG_FLAG:\n",
    "            text_ids = ['0000D23A521A', '00066EA9880D', '000E6DE9E817', '001552828BD0', \n",
    "                        '0016926B079C', '0019E4D09427', '001A03E06F3C', '00203C45FC55', \n",
    "                        '00213CD75AC3', '0027FC00C35B', '00299B378633', '0029F4D19C3F', \n",
    "                        '003CF65C2780', '003D9F49423C', '003FDC7E6F20', '0045BE2791A2', \n",
    "                        '004AC288D833', '004BE23B05BF', '004EA492DA04', '005026E0386C',\n",
    "                        '0054850878E3', '0056F3D261D5', '0057DB1DC50B', '005D28D3FEC2',\n",
    "                        '006FCE4404E3', '007812CC14B2', '007ACE74B050', '007E0CBA8852',\n",
    "                        '008015604AA0', '0080BB43EC89', '0083B82A9C6F', '00852F390697']\n",
    "\n",
    "            flag = train['id'].isin(text_ids)\n",
    "            train = train.loc[flag].reset_index(drop=True)\n",
    "\n",
    "            train_id2text = [(text_id, text) for text_id, text in train_id2text if text_id in text_ids]\n",
    "\n",
    "            print(f'* * * DEBUG_FLAG is True * * *')\n",
    "            print(f'train shape: {train.shape}')\n",
    "            print(f'train files: {len(train_id2text)}')\n",
    "\n",
    "        train_id2text = pd.DataFrame(train_id2text, columns=['id', 'text'])\n",
    "        test_id2text = pd.DataFrame(test_id2text, columns=['id', 'text'])\n",
    "\n",
    "        return train, submission, train_id2text, test_id2text\n",
    "\n",
    "\n",
    "    def color_text(id):\n",
    "        '''\n",
    "        ref. https://www.kaggle.com/ilialar/feedback-prize-simple-eda\n",
    "        '''\n",
    "        color_scheme = {\n",
    "            'Lead': 'green',\n",
    "            'Position': 'red',\n",
    "            'Claim': 'blue',\n",
    "            'Counterclaim': 'magenta',\n",
    "            'Rebuttal': 'yellow',\n",
    "            'Evidence': 'cyan',\n",
    "            'Concluding Statement': 'grey'\n",
    "        } \n",
    "\n",
    "        annot_df = train[train['id'] == id]\n",
    "        text = dic_train[id]\n",
    "\n",
    "        blocks = [(int(row['discourse_start']), int(row['discourse_end']), color_scheme[row['discourse_type']]) for k, row in annot_df.iterrows()]\n",
    "        blocks.sort()\n",
    "        i = 0\n",
    "        last_symbol = -1\n",
    "        while i < len(blocks):\n",
    "            if blocks[i][0] > last_symbol + 1:\n",
    "                blocks.insert(i, (last_symbol+1, blocks[i][0] - 1, None))\n",
    "            last_symbol = blocks[i][1]\n",
    "            i += 1\n",
    "        if last_symbol < len(text):\n",
    "            blocks.append((last_symbol+1, len(text) - 1, None))\n",
    "\n",
    "        colored_text = ''.join([colored(text[x[0]:x[1]+1], x[2]) for x in blocks])\n",
    "        return colored_text\n",
    "\n",
    "\n",
    "    def text_cleaning(text):\n",
    "        '''\n",
    "        ref) # https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-train\n",
    "\n",
    "        Cleans text into a basic form for NLP. Operations include the following:-\n",
    "        1. Remove special charecters like &, #, etc\n",
    "        2. Removes extra spaces\n",
    "        3. Removes embedded URL links\n",
    "        4. Removes HTML tags\n",
    "        5. Removes emojis\n",
    "\n",
    "        text - Text piece to be cleaned.\n",
    "        '''\n",
    "        template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "        text = template.sub(r'', text)\n",
    "\n",
    "        soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "        only_text = soup.get_text()\n",
    "        text = only_text\n",
    "\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\"\n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "        # text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n",
    "        text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "        ipPattern = re.compile('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}') # Removes IP address\n",
    "        text = ipPattern.sub(r'', text)\n",
    "        bikkuri = re.compile('!') # Removes bikkuri\n",
    "        text = bikkuri.sub(r' ', text)\n",
    "        text = text.replace('\\n','')\n",
    "        text = text.replace(\"\\'\",\"\")\n",
    "        text = text.replace(\"|\",\"\")\n",
    "        text = text.replace(\"=\",\"\")\n",
    "        text = text.replace(\"F**K\", \"FUCK\")\n",
    "        text = text.replace(\"F__K\", \"FUCK\")\n",
    "        text = text.replace(\"f**k\", \"fuck\")\n",
    "        text = text.replace(\"f__k\", \"fuck\")\n",
    "        text = text.replace(\"f*ck\", \"fuck\")    \n",
    "        text = text.replace(\"S$X\", \"SEX\")\n",
    "        text = text.replace(\"s$x\", \"sex\")\n",
    "        text = text.replace(\" u \", \" you \")\n",
    "        text = text.replace(\" u \", \" you \")\n",
    "        text = text.replace(\" U \", \" you \")\n",
    "        text = text.replace(\" U \", \" you \")\n",
    "        text = text.replace(\"YOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUUUUUUUUUU\", \"YOU\")\n",
    "        text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "        return text\n",
    "\n",
    "\n",
    "    def make_kfold(df):\n",
    "        '''\n",
    "        from Abhishek\n",
    "        https://www.kaggle.com/abhishek/creating-folds-properly-hopefully-p/notebook\n",
    "        '''\n",
    "        # df = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "        dfx = pd.get_dummies(df, columns=[\"discourse_type\"]).groupby([\"id\"], as_index=False).sum()\n",
    "        cols = [c for c in dfx.columns if c.startswith(\"discourse_type_\") or c == \"id\" and c != \"discourse_type_num\"]\n",
    "        dfx = dfx[cols]\n",
    "\n",
    "        mskf = MultilabelStratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "        labels = [c for c in dfx.columns if c != \"id\"]\n",
    "        dfx_labels = dfx[labels]\n",
    "        dfx[\"kfold\"] = -1\n",
    "\n",
    "        for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n",
    "            print(len(trn_), len(val_))\n",
    "            dfx.loc[val_, \"kfold\"] = fold\n",
    "\n",
    "        # df = df.merge(dfx[[\"id\", \"kfold\"]], on=\"id\", how=\"left\")\n",
    "        # print(df.kfold.value_counts())\n",
    "        # df.to_csv(TRAIN_FOLDS_PATH, index=False)\n",
    "        return dfx[['id', 'kfold']]\n",
    "    \n",
    "    \n",
    "    ### データ読み込み\n",
    "    train, submission, train_id2text, test_id2text = read_df()\n",
    "\n",
    "    ### fold 作成\n",
    "    id_kfold = make_kfold(train)\n",
    "    train = train.merge(id_kfold, on='id', how='left')\n",
    "\n",
    "    display(train.head(3))\n",
    "\n",
    "    ### ラベルの数値化辞書\n",
    "    id2class = dict(enumerate(train['discourse_type'].unique().tolist() + ['No Class']))\n",
    "    class2id = {v: k for k, v in id2class.items()}\n",
    "\n",
    "    print(id2class)\n",
    "    print(class2id)\n",
    "\n",
    "\n",
    "    ### ラベルなしの登録\n",
    "    def _get_elements(text_id):\n",
    "        df = train.query('id == @text_id')\n",
    "        elements = df[['discourse_start', 'discourse_end', 'discourse_type']].sort_values('discourse_start')\n",
    "        return elements.to_records(index=False).tolist()\n",
    "\n",
    "\n",
    "    def _fill_gaps(text_id):\n",
    "        elements = _get_elements(text_id)\n",
    "        start_idx = 0\n",
    "        final_idx = len(train_id2text.query('id == @text_id').iloc[0]['text'])\n",
    "        new_elements = []\n",
    "\n",
    "        ### エッセイの最初の discourse が登録されていないなら、ラベル No Class として登録する\n",
    "        if elements[0][0] != start_idx and elements[0][0] - 0 > TEXT_MIN_LENGTH:\n",
    "            new_element = (0, elements[0][0], 'No Class')\n",
    "            new_elements.append(new_element)\n",
    "\n",
    "        ### エッセイの最後の discourse が登録されていないなら、ラベル No Class として登録する\n",
    "        if elements[-1][1] != final_idx and final_idx - elements[-1][1] > TEXT_MIN_LENGTH:\n",
    "            new_element = (elements[-1][1], final_idx, 'No Class')\n",
    "            new_elements.append(new_element)\n",
    "\n",
    "        elements += new_elements\n",
    "        elements = sorted(elements, key=lambda x: x[0])\n",
    "\n",
    "        ### エッセイの途中で discourse が登録されていないなら、ラベル No Class として登録する\n",
    "        new_elements = []\n",
    "        start_idx = elements[0][0]\n",
    "        end_idx = elements[0][1]\n",
    "\n",
    "        for element in elements[1:]:\n",
    "            if end_idx != element[0] and element[0] - end_idx > TEXT_MIN_LENGTH:\n",
    "                new_element = (end_idx, element[0], 'No Class')\n",
    "                new_elements.append(new_element)\n",
    "            start_idx = element[0]\n",
    "            end_idx = element[1]\n",
    "\n",
    "        elements += new_elements\n",
    "        elements = sorted(elements, key=lambda x: x[0])\n",
    "\n",
    "        return elements\n",
    "\n",
    "\n",
    "    def get_sentences(text_id):\n",
    "        sentences = []\n",
    "        text = train_id2text.query('id == @text_id').iloc[0]['text']\n",
    "        elements = _fill_gaps(text_id)\n",
    "\n",
    "        word_id = 0\n",
    "        for element in elements:\n",
    "            sentence = text[element[0]: element[1]]\n",
    "            if len(sentence.strip()) != 0:\n",
    "                sentences.append([text_id, sentence, element[2], ' '.join(str(i) for i in range(word_id, word_id+len(sentence.split())))])\n",
    "                word_id += len(sentence.split())\n",
    "\n",
    "        return pd.DataFrame(sentences, columns=['id', 'discourse_text', 'discourse_type', 'predictionstring'])\n",
    "\n",
    "\n",
    "    ### id を文の対応を取得\n",
    "    def get_id2text(is_train=True):\n",
    "        read_dir = TRAIN_DIR if is_train else TEST_DIR\n",
    "        files = os.listdir(read_dir)\n",
    "        files.sort()\n",
    "\n",
    "        print(f'number of files: {len(files)}')\n",
    "\n",
    "        id2text = []\n",
    "        for file in files:\n",
    "            with open(os.path.join(read_dir, file), 'r') as f: text = f.read()\n",
    "            id2text.append((file.replace('.txt', ''), text))\n",
    "\n",
    "        df = pd.DataFrame(id2text, columns=['id', 'text'])\n",
    "        return df\n",
    "\n",
    "\n",
    "    def get_sentence_tokenize(id2text):\n",
    "        df = []\n",
    "        for text_id, text in zip(id2text['id'].values, id2text['text'].values):\n",
    "            ### 文に分解\n",
    "            sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "            ### 単語に分解して番号付け\n",
    "            lst_id_sentence = []\n",
    "            word_id = 0\n",
    "            for sentence in sentences:\n",
    "                id_sentence = [text_id, sentence, ' '.join(str(i) for i in range(word_id, word_id+len(sentence.split())))]\n",
    "                lst_id_sentence.append(id_sentence)\n",
    "                word_id += len(sentence.split())\n",
    "            df += lst_id_sentence\n",
    "        df = pd.DataFrame(df, columns=['id', 'discourse_text', 'ids'])\n",
    "        return df\n",
    "\n",
    "\n",
    "    ### アノテーションされていないテキストを補完\n",
    "    ### train file size: 15594 なので数分かかる\n",
    "    dfs_sentences = []\n",
    "    for text_id in train['id'].unique():\n",
    "        df = get_sentences(text_id)\n",
    "        dfs_sentences.append(df)\n",
    "    df_sentences = pd.concat(dfs_sentences)\n",
    "    df_sentences['label'] = df_sentences['discourse_type'].map(class2id)\n",
    "    df_sentences = df_sentences.merge(id_kfold, on=\"id\", how=\"left\")\n",
    "\n",
    "    display(df_sentences.head(3))\n",
    "\n",
    "    ### train のトークンを取得\n",
    "    id2text_train = get_id2text(is_train=True)\n",
    "    sent_tokenize_train = get_sentence_tokenize(id2text_train)\n",
    "    sent_tokenize_train = sent_tokenize_train.merge(id_kfold, how='left', on='id')\n",
    "\n",
    "    display(sent_tokenize_train.head(3))\n",
    "\n",
    "    ### test のトークンを取得\n",
    "    id2text_test = get_id2text(is_train=False)\n",
    "    sent_tokenize_test = get_sentence_tokenize(id2text_test)\n",
    "    start_token = sent_tokenize_test.merge(id2text_test, on='id')[['discourse_text', 'text']].apply(lambda x: x[1].find(x[0]), axis=1)\n",
    "    end_token = sent_tokenize_test.merge(id2text_test, on='id')[['discourse_text', 'text']].apply(lambda x: x[1].find(x[0])+len(x[0]), axis=1)\n",
    "    sent_tokenize_test['start_token'] = start_token\n",
    "    sent_tokenize_test['end_token'] = end_token\n",
    "\n",
    "    display(sent_tokenize_test.head(3))\n",
    "\n",
    "    ### training dataset\n",
    "    train_X = df_sentences['discourse_text']\n",
    "    train_y = df_sentences['label']\n",
    "\n",
    "    # Faster Metric Computation | Kaggle (@cpmpml)\n",
    "    # https://www.kaggle.com/cpmpml/faster-metric-computation\n",
    "\n",
    "    def calc_overlap3(set_pred, set_gt):\n",
    "        \"\"\"\n",
    "        Calculates if the overlap between prediction and\n",
    "        ground truth is enough fora potential True positive\n",
    "        \"\"\"\n",
    "        # Length of each and intersection\n",
    "        try:\n",
    "            len_gt = len(set_gt)\n",
    "            len_pred = len(set_pred)\n",
    "            inter = len(set_gt & set_pred)\n",
    "            overlap_1 = inter / len_gt\n",
    "            overlap_2 = inter/ len_pred\n",
    "            return overlap_1 >= 0.5 and overlap_2 >= 0.5\n",
    "        except:  # at least one of the input is NaN\n",
    "            return False\n",
    "\n",
    "    def score_feedback_comp_micro3(pred_df, gt_df, discourse_type):\n",
    "        \"\"\"\n",
    "        A function that scores for the kaggle\n",
    "            Student Writing Competition\n",
    "\n",
    "        Uses the steps in the evaluation page here:\n",
    "            https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "        \"\"\"\n",
    "        gt_df = gt_df.loc[gt_df['discourse_type'] == discourse_type, \n",
    "                          ['id', 'predictionstring']].reset_index(drop=True)\n",
    "        pred_df = pred_df.loc[pred_df['class'] == discourse_type,\n",
    "                          ['id', 'predictionstring']].reset_index(drop=True)\n",
    "        pred_df['pred_id'] = pred_df.index\n",
    "        gt_df['gt_id'] = gt_df.index\n",
    "        pred_df['predictionstring'] = [set(pred.split(' ')) for pred in pred_df['predictionstring']]\n",
    "        gt_df['predictionstring'] = [set(pred.split(' ')) for pred in gt_df['predictionstring']]\n",
    "\n",
    "        # Step 1. all ground truths and predictions for a given class are compared.\n",
    "        joined = pred_df.merge(gt_df,\n",
    "                               left_on='id',\n",
    "                               right_on='id',\n",
    "                               how='outer',\n",
    "                               suffixes=('_pred','_gt')\n",
    "                              )\n",
    "        overlaps = [calc_overlap3(*args) for args in zip(joined.predictionstring_pred, \n",
    "                                                         joined.predictionstring_gt)]\n",
    "\n",
    "        # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
    "        # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "        # the prediction is a match and considered a true positive.\n",
    "        # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "        # we don't need to compute the match to compute the score\n",
    "        TP = joined.loc[overlaps]['gt_id'].nunique()\n",
    "\n",
    "        # 3. Any unmatched ground truths are false negatives\n",
    "        # and any unmatched predictions are false positives.\n",
    "        TPandFP = len(pred_df)\n",
    "        TPandFN = len(gt_df)\n",
    "\n",
    "        #calc microf1\n",
    "        my_f1_score = 2*TP / (TPandFP + TPandFN)\n",
    "        return my_f1_score\n",
    "\n",
    "    def score_feedback_comp3(pred_df, gt_df, return_class_scores=False):\n",
    "        class_scores = {}\n",
    "        for discourse_type in gt_df.discourse_type.unique():\n",
    "            class_score = score_feedback_comp_micro3(pred_df, gt_df, discourse_type)\n",
    "            class_scores[discourse_type] = class_score\n",
    "        f1 = np.mean([v for v in class_scores.values()])\n",
    "        if return_class_scores:\n",
    "            return f1, class_scores\n",
    "        return f1\n",
    "\n",
    "    def get_transition(valid):\n",
    "        pred = valid.copy()\n",
    "        pred['next_class'] = pred.groupby('id')['class'].transform(lambda x: x.shift(-1))\n",
    "        pred_crosstab = pd.crosstab(pred['class'], pred['next_class'], normalize='index', dropna=False)\n",
    "        display(pred_crosstab.style.background_gradient(axis=1))\n",
    "\n",
    "\n",
    "    def get_connect(valid):\n",
    "        pred_connect = valid.copy()\n",
    "\n",
    "        # next_predictionstring 列と next_discourse_text を作成\n",
    "        pred_connect['next_predictionstring'] = pred_connect.groupby('id')['predictionstring'].transform(lambda x: x.shift(-1))\n",
    "        pred_connect['next_discourse_text'] = pred_connect.groupby('id')['discourse_text'].transform(lambda x: x.shift(-1))\n",
    "\n",
    "        # next_clas が同一の行に結合フラグを立てる\n",
    "        pred_connect['next_class'] = pred_connect.groupby('id')['class'].transform(lambda x: x.shift(-1))\n",
    "        pred_connect['match'] = (pred_connect['class'] == pred_connect['next_class']) & (pred_connect['class'] != 'Claim')\n",
    "\n",
    "        # next_class が同一の行の次の行に消去フラグを立てる\n",
    "        pred_connect['delete'] = ((pred_connect['class'] == pred_connect['next_class']) & (pred_connect['class'] != 'Claim')).shift(1).fillna(False)\n",
    "\n",
    "        # 結合フラグが立つ行に対して、next_predictionstring と next_discourse_text を結合\n",
    "        f_match = lambda x: x[1]+' '+x[2] if x[0] else x[1]\n",
    "        pred_connect['predictionstring'] = pred_connect[['match', 'predictionstring', 'next_predictionstring']].apply(f_match, axis=1)\n",
    "\n",
    "        # 消去フラグが立つ行に対して、行削除\n",
    "        pred_connect = pred_connect.drop(pred_connect.index[pred_connect['delete']])\n",
    "\n",
    "        return pred_connect\n",
    "    \n",
    "    ### 交差検証\n",
    "    scores = []\n",
    "    tfidfs = []\n",
    "    models = []\n",
    "    oof_train = np.zeros((sent_tokenize_train.shape[0], len(id2class)))\n",
    "\n",
    "    for fold_id in range(N_SPLITS):\n",
    "        start = time.time()\n",
    "        print(f'#', '-' * 80, '#')\n",
    "        print(f'fold_id: {fold_id}')\n",
    "\n",
    "        ### 訓練データ、評価データを整形\n",
    "        print(f'preprocessing ...')\n",
    "        X_trn = df_sentences.query('kfold != @fold_id')['discourse_text']\n",
    "        y_trn = df_sentences.query('kfold != @fold_id')['label']\n",
    "\n",
    "        valid = sent_tokenize_train.query('kfold == @fold_id').rename(columns={'ids': 'predictionstring'})\n",
    "        X_val = valid['discourse_text']\n",
    "\n",
    "        ### tf-idf\n",
    "        tfidf = TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            min_df=3,\n",
    "            max_df=0.5, \n",
    "            max_features=100_000,\n",
    "            analyzer='word',\n",
    "            lowercase=False,\n",
    "            ngram_range=(1, 1)\n",
    "        )\n",
    "\n",
    "        X_trn_tfidf = tfidf.fit_transform(X_trn)\n",
    "        X_val_tfidf = tfidf.transform(X_val)\n",
    "        tfidfs.append(tfidf)\n",
    "\n",
    "        print('Total number of train samples:', X_trn_tfidf.shape[0])\n",
    "        print('Total number of valid samples:', X_val_tfidf.shape[0])\n",
    "\n",
    "        ### 訓練\n",
    "        print(f'training ...')\n",
    "        clf = LogisticRegression(\n",
    "            class_weight='balanced',\n",
    "            max_iter=1000, \n",
    "            tol=1e-3, \n",
    "            n_jobs=-1,\n",
    "            solver='liblinear',\n",
    "        )\n",
    "\n",
    "        clf.fit(X_trn_tfidf, y_trn)\n",
    "\n",
    "        ### 推論\n",
    "        print(f'predicting ...')\n",
    "        val_pred_proba = clf.predict_proba(X_val_tfidf)\n",
    "        oof_train[valid.index, :] = val_pred_proba\n",
    "        val_pred = val_pred_proba.argmax(axis=1)\n",
    "        valid['label'] = val_pred\n",
    "        valid['class'] = valid['label'].map(id2class)\n",
    "        models.append(clf)\n",
    "\n",
    "        ### 評価\n",
    "        print(f'validation ...')\n",
    "        ### print(valid['class'].value_counts(normalize=True))\n",
    "        ### valid = get_connect(valid)\n",
    "        ### print(valid['class'].value_counts(normalize=True))\n",
    "        score = score_feedback_comp3(valid[valid['class'] != 'No Class'], train.query('kfold == @fold_id'))\n",
    "        scores.append(score)\n",
    "        ### get_transition(valid)\n",
    "        elapsed = time.time() - start\n",
    "        print(f'fold {fold_id} - score: {score:.6f}, elapsed time: {elapsed:.2f} [sec]')\n",
    "\n",
    "    print(f'* ' * 40)\n",
    "    print(f'Average AUC: {sum(scores)/N_SPLITS:.6f}')\n",
    "\n",
    "    ### test の tfidf\n",
    "    test_X = sent_tokenize_test['discourse_text']\n",
    "\n",
    "    ### test の predict\n",
    "    test_pred_df = sum([model.predict_proba(tfidf.transform(test_X)) / len(models) for tfidf, model in zip(tfidfs, models)])\n",
    "    test_pred_df = pd.DataFrame(test_pred_df).rename(columns=id2class)\n",
    "    test_pred_logreg = pd.concat([sent_tokenize_test, test_pred_df], axis=1)\n",
    "\n",
    "    display(test_pred_logreg.head(3))\n",
    "    \n",
    "    return test_pred_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798caede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:29:29.023035Z",
     "iopub.status.busy": "2022-03-15T16:29:29.022237Z",
     "iopub.status.idle": "2022-03-15T16:36:06.619509Z",
     "shell.execute_reply": "2022-03-15T16:36:06.618516Z",
     "shell.execute_reply.started": "2022-03-15T15:25:52.307168Z"
    },
    "papermill": {
     "duration": 397.638075,
     "end_time": "2022-03-15T16:36:06.619667",
     "exception": false,
     "start_time": "2022-03-15T16:29:28.981592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/datasets-1183/datasets-1.18.3-py3-none-any.whl\r\n",
      "Installing collected packages: datasets\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 1.16.1\r\n",
      "    Uninstalling datasets-1.16.1:\r\n",
      "      Successfully uninstalled datasets-1.16.1\r\n",
      "Successfully installed datasets-1.18.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Processing /kaggle/input/chaii-python-module-installers/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "xxhash is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "train shape: (144293, 8)\n",
      "submission shape: (5, 3)\n",
      "number of train_files: 15594\n",
      "number of test_files: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=42 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12477 3117\n",
      "12474 3120\n",
      "12475 3119\n",
      "12475 3119\n",
      "12475 3119\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627660524</td>\n",
       "      <td>8</td>\n",
       "      <td>229</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627653021</td>\n",
       "      <td>230</td>\n",
       "      <td>312</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627671020</td>\n",
       "      <td>313</td>\n",
       "      <td>401</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id   discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1622627660524                8            229   \n",
       "1  423A1CA112E2  1622627653021              230            312   \n",
       "2  423A1CA112E2  1622627671020              313            401   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  kfold  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...      1  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59      1  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Lead', 1: 'Position', 2: 'Evidence', 3: 'Claim', 4: 'Concluding Statement', 5: 'Counterclaim', 6: 'Rebuttal', 7: 'No Class'}\n",
      "{'Lead': 0, 'Position': 1, 'Evidence': 2, 'Claim': 3, 'Concluding Statement': 4, 'Counterclaim': 5, 'Rebuttal': 6, 'No Class': 7}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>label</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Phones\\n\\n</td>\n",
       "      <td>No Class</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                     discourse_text  \\\n",
       "0  423A1CA112E2                                         Phones\\n\\n   \n",
       "1  423A1CA112E2  Modern humans today are always on their phone....   \n",
       "2  423A1CA112E2  They are some really bad consequences when stu...   \n",
       "\n",
       "  discourse_type                                   predictionstring  label  \\\n",
       "0       No Class                                                  0      7   \n",
       "1           Lead  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...      0   \n",
       "2       Position       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59      1   \n",
       "\n",
       "   kfold  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files: 15594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>ids</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>This is not the case.</td>\n",
       "      <td>16 17 18 19 20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>The face on Mars is a naturally occuring land ...</td>\n",
       "      <td>21 22 23 24 25 26 27 28 29 30 31 32 33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                     discourse_text  \\\n",
       "0  0000D23A521A  Some people belive that the so called \"face\" o...   \n",
       "1  0000D23A521A                              This is not the case.   \n",
       "2  0000D23A521A  The face on Mars is a naturally occuring land ...   \n",
       "\n",
       "                                      ids  kfold  \n",
       "0   0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15      3  \n",
       "1                          16 17 18 19 20      3  \n",
       "2  21 22 23 24 25 26 27 28 29 30 31 32 33      3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>ids</th>\n",
       "      <th>start_token</th>\n",
       "      <th>end_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>During a group project, have you ever asked a ...</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Or, when you were studying for a math test, di...</td>\n",
       "      <td>16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 3...</td>\n",
       "      <td>96</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Asking for other's opinions is especially bene...</td>\n",
       "      <td>41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 5...</td>\n",
       "      <td>231</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                     discourse_text  \\\n",
       "0  0FB0700DAF44  During a group project, have you ever asked a ...   \n",
       "1  0FB0700DAF44  Or, when you were studying for a math test, di...   \n",
       "2  0FB0700DAF44  Asking for other's opinions is especially bene...   \n",
       "\n",
       "                                                 ids  start_token  end_token  \n",
       "0              0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15            0         95  \n",
       "1  16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 3...           96        230  \n",
       "2  41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 5...          231        377  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -------------------------------------------------------------------------------- #\n",
      "fold_id: 0\n",
      "preprocessing ...\n",
      "Total number of train samples: 138218\n",
      "Total number of valid samples: 66306\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting ...\n",
      "validation ...\n",
      "fold 0 - score: 0.156546, elapsed time: 16.02 [sec]\n",
      "# -------------------------------------------------------------------------------- #\n",
      "fold_id: 1\n",
      "preprocessing ...\n",
      "Total number of train samples: 138687\n",
      "Total number of valid samples: 65242\n",
      "training ...\n",
      "predicting ...\n",
      "validation ...\n",
      "fold 1 - score: 0.157667, elapsed time: 16.11 [sec]\n",
      "# -------------------------------------------------------------------------------- #\n",
      "fold_id: 2\n",
      "preprocessing ...\n",
      "Total number of train samples: 138603\n",
      "Total number of valid samples: 65560\n",
      "training ...\n",
      "predicting ...\n",
      "validation ...\n",
      "fold 2 - score: 0.158174, elapsed time: 15.48 [sec]\n",
      "# -------------------------------------------------------------------------------- #\n",
      "fold_id: 3\n",
      "preprocessing ...\n",
      "Total number of train samples: 138565\n",
      "Total number of valid samples: 65713\n",
      "training ...\n",
      "predicting ...\n",
      "validation ...\n",
      "fold 3 - score: 0.155650, elapsed time: 16.15 [sec]\n",
      "# -------------------------------------------------------------------------------- #\n",
      "fold_id: 4\n",
      "preprocessing ...\n",
      "Total number of train samples: 138747\n",
      "Total number of valid samples: 64675\n",
      "training ...\n",
      "predicting ...\n",
      "validation ...\n",
      "fold 4 - score: 0.160840, elapsed time: 16.51 [sec]\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "Average AUC: 0.157775\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>ids</th>\n",
       "      <th>start_token</th>\n",
       "      <th>end_token</th>\n",
       "      <th>Lead</th>\n",
       "      <th>Position</th>\n",
       "      <th>Evidence</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Concluding Statement</th>\n",
       "      <th>Counterclaim</th>\n",
       "      <th>Rebuttal</th>\n",
       "      <th>No Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>During a group project, have you ever asked a ...</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0.054759</td>\n",
       "      <td>0.048957</td>\n",
       "      <td>0.469391</td>\n",
       "      <td>0.107592</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.017760</td>\n",
       "      <td>0.067038</td>\n",
       "      <td>0.232063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Or, when you were studying for a math test, di...</td>\n",
       "      <td>16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 3...</td>\n",
       "      <td>96</td>\n",
       "      <td>230</td>\n",
       "      <td>0.098995</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.464329</td>\n",
       "      <td>0.207154</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.018245</td>\n",
       "      <td>0.141401</td>\n",
       "      <td>0.050777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Asking for other's opinions is especially bene...</td>\n",
       "      <td>41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 5...</td>\n",
       "      <td>231</td>\n",
       "      <td>377</td>\n",
       "      <td>0.059134</td>\n",
       "      <td>0.044478</td>\n",
       "      <td>0.045444</td>\n",
       "      <td>0.629368</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>0.089586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                     discourse_text  \\\n",
       "0  0FB0700DAF44  During a group project, have you ever asked a ...   \n",
       "1  0FB0700DAF44  Or, when you were studying for a math test, di...   \n",
       "2  0FB0700DAF44  Asking for other's opinions is especially bene...   \n",
       "\n",
       "                                                 ids  start_token  end_token  \\\n",
       "0              0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15            0         95   \n",
       "1  16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 3...           96        230   \n",
       "2  41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 5...          231        377   \n",
       "\n",
       "       Lead  Position  Evidence     Claim  Concluding Statement  Counterclaim  \\\n",
       "0  0.054759  0.048957  0.469391  0.107592              0.002439      0.017760   \n",
       "1  0.098995  0.010858  0.464329  0.207154              0.008240      0.018245   \n",
       "2  0.059134  0.044478  0.045444  0.629368              0.110454      0.008393   \n",
       "\n",
       "   Rebuttal  No Class  \n",
       "0  0.067038  0.232063  \n",
       "1  0.141401  0.050777  \n",
       "2  0.013144  0.089586  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18409261F5C2 (1302, 8) 1302\n",
      "D46BCB48440A (450, 8) 450\n",
      "0FB0700DAF44 (756, 8) 756\n",
      "D72CB1C11673 (474, 8) 474\n",
      "DF920E0A7337 (799, 8) 799\n"
     ]
    }
   ],
   "source": [
    "### ここで予測値のアンサンブル\n",
    "### test_pred_logreg = pd.read_csv('../input/test-pred-logreg/test_pred_logreg_20220313_1617.csv')\n",
    "test_pred_logreg = get_pred_logreg()\n",
    "\n",
    "### token の 予測確率の系列に変換\n",
    "pred_sample_seq = []\n",
    "for sample_idx, sample in enumerate(test_samples):\n",
    "    essay_id = sample['id']\n",
    "    offset_mapping = sample['offset_mapping']\n",
    "    df = test_pred_logreg.query('id == @essay_id').reset_index(drop=True)\n",
    "\n",
    "    ### print('#-------------------------------------------------------------------------------#')\n",
    "    ### print(essay_id)\n",
    "    ### print('#-------------------------------------------------------------------------------#')\n",
    "    token_seq_list = []\n",
    "    for i, row in df.iterrows():\n",
    "        thresh_start_token = row['start_token']\n",
    "        thresh_end_token = row['end_token']\n",
    "        start_token, end_token = 0, 0\n",
    "        for j, (s, e) in enumerate(offset_mapping):\n",
    "            if (s <= thresh_start_token) and (thresh_start_token <= e):\n",
    "                start_token = s\n",
    "                offset_mapping_start_idx = j\n",
    "            if (s <= thresh_end_token) and (thresh_end_token <= e): \n",
    "                end_token = e\n",
    "                offset_mapping_end_idx = j\n",
    "        token_size = 1 + offset_mapping_end_idx - offset_mapping_start_idx\n",
    "        ### デバッグ用 print\n",
    "        ### print((thresh_start_token, thresh_end_token), (start_token, end_token), token_size)\n",
    "        token_seq_list.append( token_size )\n",
    "    \n",
    "    ### よくわからないが値の帳尻合わせ\n",
    "    fill_token_size = len(offset_mapping) - sum(token_seq_list)\n",
    "    token_seq_list[-1] += fill_token_size\n",
    "    \n",
    "    ### token の予測値系列を生成\n",
    "    pred_seq_list = []\n",
    "    for i, row in df.iterrows():\n",
    "        pred = row[['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement', 'Counterclaim', 'Rebuttal', 'No Class']]\n",
    "        pred = np.stack([pred.to_numpy() for _ in range(token_seq_list[i])])\n",
    "        ### print(pred.shape)\n",
    "        pred_seq_list.append(pred)\n",
    "\n",
    "    pred_seq = np.vstack(pred_seq_list)\n",
    "    pred_sample_seq.append(pred_seq)\n",
    "    print(essay_id, pred_seq.shape, len(offset_mapping))\n",
    "    \n",
    "### 予測確率を id_target_map に従って B-Lead, I-Lead などの15クラスに変換\n",
    "def from8class_to15class(arr):\n",
    "    _arr = arr[:, 0]\n",
    "    return np.vstack([arr[:, 0], \n",
    "                      arr[:, 0], \n",
    "                      arr[:, 1], \n",
    "                      arr[:, 1], \n",
    "                      arr[:, 2],\n",
    "                      arr[:, 2],\n",
    "                      arr[:, 3],\n",
    "                      arr[:, 3],\n",
    "                      arr[:, 4],\n",
    "                      arr[:, 4],\n",
    "                      arr[:, 5],\n",
    "                      arr[:, 5],\n",
    "                      arr[:, 6],\n",
    "                      arr[:, 6],\n",
    "                      arr[:, 7]]).T\n",
    "\n",
    "pred_logreg = [from8class_to15class(pred) for pred in pred_sample_seq]\n",
    "\n",
    "### raw_preds をコピーして予測値をアンサンブル\n",
    "_raw_preds = [raw_preds[0].copy()]\n",
    "for i in range(len(pred_logreg)):\n",
    "    d1, d2 = pred_logreg[i].shape\n",
    "    _raw_preds[0][i, :d1, :d2] = _raw_preds[0][i, :d1, :d2] + 0.05 * pred_logreg[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afe97558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:36:06.703323Z",
     "iopub.status.busy": "2022-03-15T16:36:06.702595Z",
     "iopub.status.idle": "2022-03-15T16:36:06.707486Z",
     "shell.execute_reply": "2022-03-15T16:36:06.707909Z",
     "shell.execute_reply.started": "2022-03-15T15:32:36.792452Z"
    },
    "papermill": {
     "duration": 0.049831,
     "end_time": "2022-03-15T16:36:06.708059",
     "exception": false,
     "start_time": "2022-03-15T16:36:06.658228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "final_scores = []\n",
    "\n",
    "for rp in raw_preds: ### raw_preds から _raw_preds に書き換え\n",
    "    pred_class = np.argmax(rp, axis=2)\n",
    "    pred_scrs = np.max(rp, axis=2)\n",
    "    for pred, pred_scr in zip(pred_class, pred_scrs):\n",
    "        pred = pred.tolist()\n",
    "        pred_scr = pred_scr.tolist()\n",
    "        final_preds.append(pred)\n",
    "        final_scores.append(pred_scr)\n",
    "\n",
    "for j in range(len(test_samples)):\n",
    "    tt = [id_target_map[p] for p in final_preds[j][1:]]\n",
    "    tt_score = final_scores[j][1:]\n",
    "    test_samples[j][\"preds\"] = tt\n",
    "    test_samples[j][\"pred_scores\"] = tt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53be6576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:36:06.796416Z",
     "iopub.status.busy": "2022-03-15T16:36:06.795730Z",
     "iopub.status.idle": "2022-03-15T16:36:06.798478Z",
     "shell.execute_reply": "2022-03-15T16:36:06.797778Z",
     "shell.execute_reply.started": "2022-03-15T15:32:36.805792Z"
    },
    "papermill": {
     "duration": 0.051893,
     "end_time": "2022-03-15T16:36:06.798588",
     "exception": false,
     "start_time": "2022-03-15T16:36:06.746695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jn(pst, start, end):\n",
    "    return \" \".join([str(x) for x in pst[start:end]])\n",
    "\n",
    "\n",
    "def link_evidence(oof):\n",
    "    thresh = 1\n",
    "    idu = oof['id'].unique()\n",
    "    idc = idu[1]\n",
    "    eoof = oof[oof['class'] == \"Evidence\"]\n",
    "    neoof = oof[oof['class'] != \"Evidence\"]\n",
    "    for thresh2 in range(26,27, 1):\n",
    "        retval = []\n",
    "        for idv in idu:\n",
    "            for c in  ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n",
    "                   'Counterclaim', 'Rebuttal']:\n",
    "                q = eoof[(eoof['id'] == idv) & (eoof['class'] == c)]\n",
    "                if len(q) == 0:\n",
    "                    continue\n",
    "                pst = []\n",
    "                for i,r in q.iterrows():\n",
    "                    pst = pst +[-1] + [int(x) for x in r['predictionstring'].split()]\n",
    "                start = 1\n",
    "                end = 1\n",
    "                for i in range(2,len(pst)):\n",
    "                    cur = pst[i]\n",
    "                    end = i\n",
    "                    #if pst[start] == 205:\n",
    "                    #   print(cur, pst[start], cur - pst[start])\n",
    "                    if (cur == -1 and c != 'Evidence') or ((cur == -1) and ((pst[i+1] > pst[end-1] + thresh) or (pst[i+1] - pst[start] > thresh2))):\n",
    "                        retval.append((idv, c, jn(pst, start, end)))\n",
    "                        start = i + 1\n",
    "                v = (idv, c, jn(pst, start, end+1))\n",
    "                #print(v)\n",
    "                retval.append(v)\n",
    "        roof = pd.DataFrame(retval, columns = ['id', 'class', 'predictionstring']) \n",
    "        roof = roof.merge(neoof, how='outer')\n",
    "        return roof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "045b415b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:36:06.885149Z",
     "iopub.status.busy": "2022-03-15T16:36:06.884331Z",
     "iopub.status.idle": "2022-03-15T16:36:06.899444Z",
     "shell.execute_reply": "2022-03-15T16:36:06.898983Z",
     "shell.execute_reply.started": "2022-03-15T15:32:36.821953Z"
    },
    "papermill": {
     "duration": 0.062989,
     "end_time": "2022-03-15T16:36:06.899544",
     "exception": false,
     "start_time": "2022-03-15T16:36:06.836555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_samples の長さ: 5\n",
      "test_samples[0].keys(): dict_keys(['id', 'input_ids', 'text', 'offset_mapping', 'preds', 'pred_scores'])\n",
      "test_samples[0][\"id\"]: 18409261F5C2\n",
      "test_samples[0][\"input_ids\"]: [2940, 207, 9, 1791, 679, 1818, 1533, 5086, 64, 244, 106, 146, 357, 5717, 6, 8, 13, 205, 1219, 4, 9307, 33, 2343, 5, 674, 1791, 444, 154, 444, 357, 11, 49, 1074, 1118, 7, 49, 10428, 142, 51, 32, 6288, 7, 97, 18, 2949, 4, 345, 32, 67, 171]\n",
      "test_samples[0][\"text\"]: ['80%', 'of', 'Americans', 'believe', 'seeking', 'multiple', 'opinions', 'can', 'help', 'them', 'make', 'better', 'choices,', 'and', 'for', 'good', 'reason.', 'Studies', 'have', 'shown', 'the', 'average', 'Americans', 'faring', 'far', 'better', 'in', 'their', 'lives', 'compared', 'to', 'their', 'counterparts', 'because', 'they', 'are', 'listening', 'to', \"other's\", 'advice.', 'There', 'are', 'also', 'many', 'myths', 'that', 'have', 'the', 'moral', 'of']\n",
      "test_samples[0][\"offset_mapping\"]: [(0, 2), (2, 3), (4, 6), (7, 16), (17, 24), (25, 32), (33, 41), (42, 50), (51, 54), (55, 59), (60, 64), (65, 69), (70, 76), (77, 84), (84, 85), (86, 89), (90, 93), (94, 98), (99, 105), (105, 106), (107, 114), (115, 119), (120, 125), (126, 129), (130, 137), (138, 147), (148, 151), (151, 154), (155, 158), (159, 165), (166, 168), (169, 174), (175, 180), (181, 189), (190, 192), (193, 198), (199, 211), (212, 219), (220, 224), (225, 228), (229, 238), (239, 241), (242, 247), (247, 249), (250, 256), (256, 257), (258, 263), (264, 267), (268, 272), (273, 277)]\n",
      "test_samples[0][\"preds\"]: ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead']\n",
      "test_samples[0][\"pred_scores\"]: [0.98046875, 0.9833984375, 0.98486328125, 0.9853515625, 0.98193359375, 0.982421875, 0.984375, 0.984375, 0.98095703125, 0.98193359375, 0.98486328125, 0.98291015625, 0.98291015625, 0.984375, 0.978515625, 0.9765625, 0.978515625, 0.978515625, 0.97607421875, 0.9765625, 0.955078125, 0.970703125, 0.9677734375, 0.9716796875, 0.96875, 0.97314453125, 0.9697265625, 0.96826171875, 0.9697265625, 0.96875, 0.9697265625, 0.9697265625, 0.970703125, 0.96875, 0.9697265625, 0.97021484375, 0.97021484375, 0.97021484375, 0.96923828125, 0.96826171875, 0.9716796875, 0.96923828125, 0.97216796875, 0.9697265625, 0.97265625, 0.97607421875, 0.9794921875, 0.97021484375, 0.97265625, 0.97119140625]\n",
      "#------------------------------------------------------------------------------------------------#\n",
      "offset_mapping を使って token 取り出し:\n",
      "0 2 80\n",
      "2 3 %\n",
      "4 6 of\n",
      "7 16 Americans\n",
      "17 24 believe\n",
      "25 32 seeking\n",
      "33 41 multiple\n",
      "42 50 opinions\n",
      "51 54 can\n",
      "55 59 help\n",
      "60 64 them\n",
      "65 69 make\n",
      "70 76 better\n",
      "77 84 choices\n",
      "84 85 ,\n",
      "86 89 and\n",
      "90 93 for\n",
      "94 98 good\n",
      "99 105 reason\n",
      "105 106 .\n",
      "#------------------------------------------------------------------------------------------------#\n",
      "input_ids の長さ: 1302\n",
      "text の単語の長さ: 1056\n",
      "offset_mapping の長さ: 1302\n",
      "preds の長さ: 1303\n",
      "pred_scores の長さ: 1303\n",
      "#------------------------------------------------------------------------------------------------#\n",
      "raw_preds[0] のサイズ: (5, 1304, 15)\n",
      "raw_preds[0][0,:2,:]: [[1.643e-03 8.764e-04 1.402e-04 1.229e-04 5.746e-05 9.072e-05 7.385e-05\n",
      "  3.356e-05 1.007e-05 3.815e-06 1.335e-05 8.225e-06 5.066e-06 1.317e-05\n",
      "  9.976e-01]\n",
      " [9.805e-01 6.367e-03 6.248e-03 9.793e-05 1.685e-03 2.688e-05 1.791e-03\n",
      "  1.013e-05 8.029e-05 1.669e-06 2.378e-04 6.378e-06 3.928e-05 1.615e-05\n",
      "  2.823e-03]]\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print('test_samples の長さ:', len(test_samples))\n",
    "print('test_samples[0].keys():', test_samples[0].keys())\n",
    "print('test_samples[0][\"id\"]:', test_samples[0]['id'])\n",
    "print('test_samples[0][\"input_ids\"]:', test_samples[0]['input_ids'][:50])  ### 長いので最初の100個。おそらく token ids\n",
    "print('test_samples[0][\"text\"]:', test_samples[0]['text'].split()[:50])\n",
    "print('test_samples[0][\"offset_mapping\"]:', test_samples[0]['offset_mapping'][:50])\n",
    "print('test_samples[0][\"preds\"]:', test_samples[0]['preds'][:50])\n",
    "print('test_samples[0][\"pred_scores\"]:', test_samples[0]['pred_scores'][:50])\n",
    "print('#------------------------------------------------------------------------------------------------#')\n",
    "print('offset_mapping を使って token 取り出し:')\n",
    "for start, end in test_samples[0]['offset_mapping'][:20]:\n",
    "    print(start, end, test_samples[0]['text'][start:end])\n",
    "print('#------------------------------------------------------------------------------------------------#')\n",
    "print('input_ids の長さ:', len(test_samples[0]['input_ids']))\n",
    "print('text の単語の長さ:', len(test_samples[0]['text'].split())) ### input_ids と単語の長さは異なる\n",
    "print('offset_mapping の長さ:', len(test_samples[0]['offset_mapping']))\n",
    "print('preds の長さ:', len(test_samples[0]['preds']))\n",
    "print('pred_scores の長さ:', len(test_samples[0]['pred_scores']))\n",
    "print('#------------------------------------------------------------------------------------------------#')\n",
    "print('raw_preds[0] のサイズ:', raw_preds[0].shape)\n",
    "print('raw_preds[0][0,:2,:]:', raw_preds[0][0,:2,:])\n",
    "print(raw_preds[0][0,:2,:].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b1c1a4",
   "metadata": {
    "papermill": {
     "duration": 0.038495,
     "end_time": "2022-03-15T16:36:06.976574",
     "exception": false,
     "start_time": "2022-03-15T16:36:06.938079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- offset_mapping によって token を取り出すことができる。\n",
    "- なぜか preds の長さが token 数よりも1個だけ長い。\n",
    "- pred_scores は token ごとに値があるが、クラス数ごとの値が入っているわけではない。\n",
    "- すべての token のすべてのクラスに対するスコアは raw_preds から確認できる。\n",
    "- アンサンブルに持ち込むには、raw_preds と、sentences の LightGBM 予測値を合成する必要がある。\n",
    "    - ポイントは、sentences を何らかの方法で token に変換して、token 長さの予測値系列をつくること。\n",
    "    - それをやるためには、sentence の offset_mapping を用意しておいて、それをもとに transformer の offset_mapping にあわせて系列の長さが調節できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75469166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:36:07.077347Z",
     "iopub.status.busy": "2022-03-15T16:36:07.060585Z",
     "iopub.status.idle": "2022-03-15T16:36:07.108320Z",
     "shell.execute_reply": "2022-03-15T16:36:07.107891Z",
     "shell.execute_reply.started": "2022-03-15T15:32:36.851596Z"
    },
    "papermill": {
     "duration": 0.09335,
     "end_time": "2022-03-15T16:36:07.108428",
     "exception": false,
     "start_time": "2022-03-15T16:36:07.015078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.7 ms, sys: 79 µs, total: 41.8 ms\n",
      "Wall time: 40.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "proba_thresh = {\n",
    "    \"Lead\": 0.687,\n",
    "    \"Position\": 0.537,\n",
    "    \"Evidence\": 0.637,\n",
    "    \"Claim\": 0.537,\n",
    "    \"Concluding Statement\": 0.687,\n",
    "    \"Counterclaim\": 0.537,\n",
    "    \"Rebuttal\": 0.537,\n",
    "}\n",
    "\n",
    "min_thresh = {\n",
    "    \"Lead\": 9,\n",
    "    \"Position\": 5,\n",
    "    \"Evidence\": 14,\n",
    "    \"Claim\": 3,\n",
    "    \"Concluding Statement\": 11,\n",
    "    \"Counterclaim\": 6,\n",
    "    \"Rebuttal\": 4,\n",
    "}\n",
    "\n",
    "submission = []\n",
    "for sample_idx, sample in enumerate(test_samples):\n",
    "    preds = sample[\"preds\"]\n",
    "    offset_mapping = sample[\"offset_mapping\"]\n",
    "    sample_id = sample[\"id\"]\n",
    "    sample_text = sample[\"text\"]\n",
    "    sample_input_ids = sample[\"input_ids\"]\n",
    "    sample_pred_scores = sample[\"pred_scores\"]\n",
    "    sample_preds = []\n",
    "\n",
    "    if len(preds) < len(offset_mapping):\n",
    "        preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n",
    "        sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n",
    "    \n",
    "    idx = 0\n",
    "    phrase_preds = []\n",
    "    while idx < len(offset_mapping):\n",
    "        start, _ = offset_mapping[idx]\n",
    "        if preds[idx] != \"O\":\n",
    "            label = preds[idx][2:]\n",
    "        else:\n",
    "            label = \"O\"\n",
    "        phrase_scores = []\n",
    "        phrase_scores.append(sample_pred_scores[idx])\n",
    "        idx += 1\n",
    "        while idx < len(offset_mapping):\n",
    "            if label == \"O\":\n",
    "                matching_label = \"O\"\n",
    "            else:\n",
    "                matching_label = f\"I-{label}\"\n",
    "            if preds[idx] == matching_label:\n",
    "                _, end = offset_mapping[idx]\n",
    "                phrase_scores.append(sample_pred_scores[idx])\n",
    "                idx += 1\n",
    "            else:\n",
    "                break\n",
    "        if \"end\" in locals():\n",
    "            phrase = sample_text[start:end]\n",
    "            phrase_preds.append((phrase, start, end, label, phrase_scores))\n",
    "\n",
    "    temp_df = []\n",
    "    for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n",
    "        word_start = len(sample_text[:start].split())\n",
    "        word_end = word_start + len(sample_text[start:end].split())\n",
    "        word_end = min(word_end, len(sample_text.split()))\n",
    "        ps = \" \".join([str(x) for x in range(word_start, word_end)])\n",
    "        if label != \"O\":\n",
    "            if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n",
    "                if len(ps.split()) >= min_thresh[label]:\n",
    "                    temp_df.append((sample_id, label, ps))\n",
    "    \n",
    "    temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n",
    "    submission.append(temp_df)\n",
    "\n",
    "submission = pd.concat(submission).reset_index(drop=True)\n",
    "submission = link_evidence(submission)\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0707e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:36:07.193678Z",
     "iopub.status.busy": "2022-03-15T16:36:07.193021Z",
     "iopub.status.idle": "2022-03-15T16:36:07.195678Z",
     "shell.execute_reply": "2022-03-15T16:36:07.196162Z",
     "shell.execute_reply.started": "2022-03-15T15:32:36.912115Z"
    },
    "papermill": {
     "duration": 0.049367,
     "end_time": "2022-03-15T16:36:07.196290",
     "exception": false,
     "start_time": "2022-03-15T16:36:07.146923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18409261F5C2</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>162 163 164 165 166 167 168 169 170 171 172 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18409261F5C2</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>441 442 443 444 445 446 447 448 449 450 451 45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18409261F5C2</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>739 740 741 742 743 744 745 746 747 748 749 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>150 151 152 153 154 155 156 157 158 159 160 16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     class                                   predictionstring\n",
       "0  18409261F5C2  Evidence  162 163 164 165 166 167 168 169 170 171 172 17...\n",
       "1  18409261F5C2  Evidence  441 442 443 444 445 446 447 448 449 450 451 45...\n",
       "2  18409261F5C2  Evidence  739 740 741 742 743 744 745 746 747 748 749 75...\n",
       "3  D46BCB48440A  Evidence  56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 7...\n",
       "4  D46BCB48440A  Evidence  150 151 152 153 154 155 156 157 158 159 160 16..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9685430",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T16:36:07.281715Z",
     "iopub.status.busy": "2022-03-15T16:36:07.277197Z",
     "iopub.status.idle": "2022-03-15T16:36:07.286509Z",
     "shell.execute_reply": "2022-03-15T16:36:07.286093Z",
     "shell.execute_reply.started": "2022-03-15T15:34:11.672498Z"
    },
    "papermill": {
     "duration": 0.051257,
     "end_time": "2022-03-15T16:36:07.286606",
     "exception": false,
     "start_time": "2022-03-15T16:36:07.235349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim                   0.361702\n",
       "Evidence                0.297872\n",
       "Position                0.127660\n",
       "Lead                    0.106383\n",
       "Concluding Statement    0.106383\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['class'].value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 669.672259,
   "end_time": "2022-03-15T16:36:10.728450",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-15T16:25:01.056191",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
